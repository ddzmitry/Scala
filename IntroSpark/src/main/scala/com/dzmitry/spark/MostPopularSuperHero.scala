package com.dzmitry.spark

import java.nio.charset.CodingErrorAction

import org.apache.log4j.{Level, Logger}
import org.apache.spark.broadcast.Broadcast
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.SparkSession

import scala.io.{Codec, Source}

object MostPopularSuperHero {

  def LoadHeroesNames() : Map[Int,String] = {

    implicit val codec = Codec("UTF-8")
    codec.onMalformedInput(CodingErrorAction.REPLACE)
    codec.onUnmappableCharacter(CodingErrorAction.REPLACE)
    var HeroNames:Map[Int,String] = Map()
    val lines = Source.fromFile("../Marvel-names.txt").getLines()
    for (line <- lines) {
      var fields = line.split('\"')
      if(fields.length > 1) {

        HeroNames += (fields(0).trim.toInt -> fields(1).trim)

      }
    }
    return HeroNames
  }

  def lineSpliter(line:String,broadcast:Broadcast[ Map[Int,String]]) : Array[(String, Int)] = {

   return line.split(" ").map(x => {

     (broadcast.value(x.toInt),1)

   })
  }
  def main(args: Array[String]): Unit = {

    Logger.getLogger("org").setLevel(Level.ERROR)
    val spark = SparkSession.builder
      .appName("Popular Heroe")  // optional and will be autogenerated if not specified
      .master("local[*]")               // only for demo and testing purposes, use spark-submit instead
      .config("spark.sql.warehouse.dir", "target/spark-warehouse")
      .getOrCreate()

    val graphLines = spark.sparkContext.textFile("../Marvel-graph.txt")
    var broadcatMap = spark.sparkContext.broadcast(LoadHeroesNames)
    val heroesSingleCount = graphLines.flatMap(x => lineSpliter(x,broadcatMap))
    val OrderedSuperHeroes = heroesSingleCount
      .reduceByKey((x,y) =>(x+y))
      .map(x => (x._2,x._1))
      .sortByKey(false)
      .map(y => (y._2,y._1))
    val df = spark.createDataFrame(OrderedSuperHeroes).toDF("SuperHero","Count")
    df.show(20,false)


  }
}
